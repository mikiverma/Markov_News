{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_text (file):\n",
    "    with open(file,'r') as f:\n",
    "        text = f.read()\n",
    "    f.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb = read_text('data/breitbart_pol_feb_20_26.txt')\n",
    "nyt = read_text('data/nyt_pol_feb_20_26.txt')\n",
    "hp = read_text('data/huffpost_pol_feb_20_26.txt')\n",
    "fox = read_text('data/fox_pol_feb_20_26.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = [bb,nyt,fox,hp]\n",
    "names = [\"breitbart\",\"nyt\",\"fox\",\"hp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "tokenize = lambda doc: list(filter(None,re.split(r\"\\W|\\d\",doc.lower())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words = stopWords,tokenizer=tokenize)\n",
    "tfidf = tfidf_vec.fit_transform(d)\n",
    "#print(td_mat.shape)\n",
    "#count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf and tf-idf\n",
    "# tf_transformer = TfidfTransformer(use_idf=False)\n",
    "# tf = tf_transformer.fit_transform(td_mat)\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# tfidf = tfidf_transformer.fit_transform(td_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarities_mat(m):\n",
    "    n = m.shape[0]\n",
    "    cs_array = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        cs_array[i]=(linear_kernel(m[i:i+1], m).flatten())\n",
    "    return cs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.59833811,  0.80777284,  0.81084176],\n",
       "       [ 0.59833811,  1.        ,  0.63252188,  0.63501316],\n",
       "       [ 0.80777284,  0.63252188,  1.        ,  0.84319142],\n",
       "       [ 0.81084176,  0.63501316,  0.84319142,  1.        ]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities_mat(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pearson_corr_mat(m):\n",
    "    n = m.shape[0]\n",
    "    pc_array_all = np.corrcoef(m.toarray(), m.toarray())\n",
    "    pc_array = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        pc_array[i]=pc_array_all[i][0:4]\n",
    "    return pc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.57311568,  0.79083545,  0.78999278],\n",
       "       [ 0.57311568,  1.        ,  0.61108668,  0.61226321],\n",
       "       [ 0.79083545,  0.61108668,  1.        ,  0.82938021],\n",
       "       [ 0.78999278,  0.61226321,  0.82938021,  1.        ]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson_corr_mat(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_features = 50,stop_words = stopWords,tokenizer=tokenize)\n",
    "td_mat = count_vect.fit_transform(d)\n",
    "#count_vect.get_feature_names()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf = tfidf_transformer.fit_transform(td_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(d1, d2):\n",
    "    intersection = set(d1).intersection(set(d2))\n",
    "    union = set(d1).union(set(d2))\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_tokenized =[tokenize(doc) for doc in d]\n",
    "d_no_stop =[[w for w in d if w not in stopWords] for d in d_tokenized]\n",
    "d_Freq =[FreqDist(doc) for doc in d_no_stop]\n",
    "d_common_50 =[f.most_common(50) for f in d_Freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_most_common_words = [list(zip(*d))[0] for d in d_common_50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity_mat(m):\n",
    "    n = len(m)\n",
    "    array = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            sim = jaccard_similarity(m[i],m[j])\n",
    "            array[i][j] = sim\n",
    "            array[j][i] = sim\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.2987013 ,  0.36986301,  0.33333333],\n",
       "       [ 0.2987013 ,  1.        ,  0.36986301,  0.35135135],\n",
       "       [ 0.36986301,  0.36986301,  1.        ,  0.42857143],\n",
       "       [ 0.33333333,  0.35135135,  0.42857143,  1.        ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similarity_mat(d_most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
