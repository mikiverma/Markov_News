{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime as dt\n",
    "import collections\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sourcefnames = {'bloomberg' : 'data/scrapedbloomberg.json',\n",
    "                'breitbart' : 'data/scrapedbreitbart.json',\n",
    "                'cnn' : 'data/scrapedcnn.json',\n",
    "                'fox' : 'data/scrapedfox.json',\n",
    "                #'guardian' : 'data/scrapedguardian.json',\n",
    "                'natl review' : 'data/scrapednatreview.json',\n",
    "                'WaPo' : 'data/scrapedwapo.json'}\n",
    "urls = {}\n",
    "datecounts = {}\n",
    "article_text = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in sourcefnames.items():\n",
    "    urls[k] = set()\n",
    "    datecounts[k] = {}\n",
    "    with open(v) as f:\n",
    "        for line in f:\n",
    "            art = json.loads(line)\n",
    "            max_articles = False\n",
    "            if art['date'] and art['sourceurl'] not in urls[k]:\n",
    "                dobj = dt.strptime(art['date'][0:10], '%Y-%m-%d')\n",
    "                if dobj.year == 2017:    \n",
    "                    if dobj in datecounts[k]:\n",
    "                        if datecounts[k][dobj] < 1:\n",
    "                            datecounts[k][dobj] += 1\n",
    "                        else:\n",
    "                            max_articles = True\n",
    "                    else:\n",
    "                        datecounts[k][dobj] = 1\n",
    "                    if not max_articles:\n",
    "                        urls[k].add(art['sourceurl'])\n",
    "                        if (dobj.month,k) in article_text:\n",
    "                            article_text[(dobj.month,k)]+=art['response_body']\n",
    "                        else:\n",
    "                            article_text[(dobj.month,k)]=art['response_body']\n",
    "                            \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article_text = collections.OrderedDict(sorted(article_text.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572736 1 WaPo\n",
      "149499 1 bloomberg\n",
      "627156 1 breitbart\n",
      "1512418 1 cnn\n",
      "541400 1 fox\n",
      "463521 1 natl review\n",
      "561405 2 WaPo\n",
      "237539 2 bloomberg\n",
      "725659 2 breitbart\n",
      "1183944 2 cnn\n",
      "1133763 2 fox\n",
      "482311 2 natl review\n",
      "417259 3 WaPo\n",
      "128191 3 bloomberg\n",
      "250255 3 breitbart\n",
      "186620 3 cnn\n",
      "154417 3 fox\n",
      "286454 3 natl review\n"
     ]
    }
   ],
   "source": [
    "for t in article_text:\n",
    "    print(len(article_text[t]),t[0],t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WaPo': {datetime.datetime(2017, 1, 2, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 5, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 7, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 8, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 15, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 16, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 17, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 18, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 21, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 23, 0, 0): 8,\n",
       "  datetime.datetime(2017, 1, 24, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 25, 0, 0): 4,\n",
       "  datetime.datetime(2017, 1, 28, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 30, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 31, 0, 0): 5,\n",
       "  datetime.datetime(2017, 2, 1, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 5, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 8, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 9, 0, 0): 5,\n",
       "  datetime.datetime(2017, 2, 10, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 11, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 12, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 13, 0, 0): 5,\n",
       "  datetime.datetime(2017, 2, 14, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 16, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 17, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 18, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 19, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 21, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 22, 0, 0): 5,\n",
       "  datetime.datetime(2017, 2, 23, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 24, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 27, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 28, 0, 0): 3,\n",
       "  datetime.datetime(2017, 3, 1, 0, 0): 5,\n",
       "  datetime.datetime(2017, 3, 2, 0, 0): 8,\n",
       "  datetime.datetime(2017, 3, 3, 0, 0): 6,\n",
       "  datetime.datetime(2017, 3, 4, 0, 0): 5,\n",
       "  datetime.datetime(2017, 3, 5, 0, 0): 7,\n",
       "  datetime.datetime(2017, 3, 6, 0, 0): 10},\n",
       " 'bloomberg': {datetime.datetime(2017, 1, 13, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 18, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 19, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 26, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 27, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 30, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 31, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 1, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 2, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 9, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 10, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 13, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 20, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 21, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 23, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 24, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 25, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 27, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 28, 0, 0): 6,\n",
       "  datetime.datetime(2017, 3, 1, 0, 0): 7,\n",
       "  datetime.datetime(2017, 3, 2, 0, 0): 10},\n",
       " 'breitbart': {datetime.datetime(2017, 1, 1, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 2, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 4, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 5, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 6, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 9, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 10, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 11, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 12, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 14, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 15, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 17, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 18, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 19, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 20, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 21, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 23, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 24, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 26, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 27, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 29, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 30, 0, 0): 7,\n",
       "  datetime.datetime(2017, 1, 31, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 1, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 2, 0, 0): 6,\n",
       "  datetime.datetime(2017, 2, 3, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 6, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 7, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 8, 0, 0): 7,\n",
       "  datetime.datetime(2017, 2, 9, 0, 0): 6,\n",
       "  datetime.datetime(2017, 2, 11, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 12, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 13, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 14, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 15, 0, 0): 6,\n",
       "  datetime.datetime(2017, 2, 16, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 17, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 19, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 21, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 22, 0, 0): 6,\n",
       "  datetime.datetime(2017, 2, 23, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 24, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 25, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 26, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 27, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 28, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 1, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 2, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 3, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 4, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 5, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 6, 0, 0): 10},\n",
       " 'cnn': {datetime.datetime(2017, 1, 3, 0, 0): 5,\n",
       "  datetime.datetime(2017, 1, 5, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 6, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 7, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 9, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 10, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 11, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 12, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 13, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 14, 0, 0): 6,\n",
       "  datetime.datetime(2017, 1, 15, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 16, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 17, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 18, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 19, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 20, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 21, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 22, 0, 0): 5,\n",
       "  datetime.datetime(2017, 1, 23, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 24, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 25, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 26, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 27, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 28, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 29, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 30, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 31, 0, 0): 5,\n",
       "  datetime.datetime(2017, 2, 1, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 2, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 3, 0, 0): 5,\n",
       "  datetime.datetime(2017, 2, 4, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 5, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 6, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 7, 0, 0): 5,\n",
       "  datetime.datetime(2017, 2, 8, 0, 0): 7,\n",
       "  datetime.datetime(2017, 2, 9, 0, 0): 7,\n",
       "  datetime.datetime(2017, 2, 10, 0, 0): 6,\n",
       "  datetime.datetime(2017, 2, 11, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 12, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 13, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 14, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 15, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 16, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 17, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 18, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 19, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 20, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 21, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 22, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 23, 0, 0): 9,\n",
       "  datetime.datetime(2017, 2, 24, 0, 0): 5,\n",
       "  datetime.datetime(2017, 2, 25, 0, 0): 5,\n",
       "  datetime.datetime(2017, 2, 26, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 27, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 28, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 1, 0, 0): 9,\n",
       "  datetime.datetime(2017, 3, 2, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 3, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 4, 0, 0): 5},\n",
       " 'fox': {datetime.datetime(2017, 1, 3, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 6, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 9, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 10, 0, 0): 4,\n",
       "  datetime.datetime(2017, 1, 12, 0, 0): 7,\n",
       "  datetime.datetime(2017, 1, 13, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 15, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 16, 0, 0): 7,\n",
       "  datetime.datetime(2017, 1, 17, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 18, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 19, 0, 0): 5,\n",
       "  datetime.datetime(2017, 1, 20, 0, 0): 10,\n",
       "  datetime.datetime(2017, 1, 22, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 23, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 24, 0, 0): 6,\n",
       "  datetime.datetime(2017, 1, 25, 0, 0): 9,\n",
       "  datetime.datetime(2017, 1, 26, 0, 0): 9,\n",
       "  datetime.datetime(2017, 1, 27, 0, 0): 7,\n",
       "  datetime.datetime(2017, 1, 29, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 31, 0, 0): 9,\n",
       "  datetime.datetime(2017, 2, 1, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 2, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 3, 0, 0): 8,\n",
       "  datetime.datetime(2017, 2, 4, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 5, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 6, 0, 0): 8,\n",
       "  datetime.datetime(2017, 2, 7, 0, 0): 6,\n",
       "  datetime.datetime(2017, 2, 8, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 9, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 10, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 11, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 12, 0, 0): 6,\n",
       "  datetime.datetime(2017, 2, 13, 0, 0): 9,\n",
       "  datetime.datetime(2017, 2, 14, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 15, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 16, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 17, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 18, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 19, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 20, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 21, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 22, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 23, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 24, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 25, 0, 0): 6,\n",
       "  datetime.datetime(2017, 2, 26, 0, 0): 8,\n",
       "  datetime.datetime(2017, 2, 27, 0, 0): 10,\n",
       "  datetime.datetime(2017, 2, 28, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 1, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 2, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 3, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 4, 0, 0): 10},\n",
       " 'natl review': {datetime.datetime(2017, 1, 3, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 4, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 6, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 7, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 8, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 11, 0, 0): 3,\n",
       "  datetime.datetime(2017, 1, 12, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 13, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 15, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 17, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 18, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 19, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 20, 0, 0): 1,\n",
       "  datetime.datetime(2017, 1, 23, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 24, 0, 0): 2,\n",
       "  datetime.datetime(2017, 1, 26, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 4, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 6, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 8, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 9, 0, 0): 4,\n",
       "  datetime.datetime(2017, 2, 10, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 13, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 15, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 16, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 18, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 20, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 21, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 22, 0, 0): 2,\n",
       "  datetime.datetime(2017, 2, 23, 0, 0): 3,\n",
       "  datetime.datetime(2017, 2, 25, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 27, 0, 0): 1,\n",
       "  datetime.datetime(2017, 2, 28, 0, 0): 1,\n",
       "  datetime.datetime(2017, 3, 1, 0, 0): 3,\n",
       "  datetime.datetime(2017, 3, 2, 0, 0): 9,\n",
       "  datetime.datetime(2017, 3, 3, 0, 0): 10,\n",
       "  datetime.datetime(2017, 3, 4, 0, 0): 4,\n",
       "  datetime.datetime(2017, 3, 5, 0, 0): 2}}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datecounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month = 2\n",
    "names = [t[1] for t in article_text if t[0] == month]\n",
    "d = [article_text[t] for t in article_text if t[0] == month]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WaPo', 'bloomberg', 'breitbart', 'cnn', 'fox', 'natl review']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "tokenize = lambda doc: list(filter(None,re.split(r\"\\W|\\d\",doc.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words = stopWords,tokenizer=tokenize)\n",
    "tfidf = tfidf_vec.fit_transform(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tfidf_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarities_mat(m):\n",
    "    n = m.shape[0]\n",
    "    cs_array = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        cs_array[i]=(linear_kernel(m[i:i+1], m).flatten())\n",
    "    return cs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pearson_corr_mat(m):\n",
    "    n = m.shape[0]\n",
    "    pc_array_all = np.corrcoef(m.toarray(), m.toarray())\n",
    "    pc_array = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        pc_array[i]=pc_array_all[i][0:n]\n",
    "    return pc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WaPo</th>\n",
       "      <th>bloomberg</th>\n",
       "      <th>breitbart</th>\n",
       "      <th>cnn</th>\n",
       "      <th>fox</th>\n",
       "      <th>natl review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WaPo</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.604432</td>\n",
       "      <td>0.533233</td>\n",
       "      <td>0.836252</td>\n",
       "      <td>0.799638</td>\n",
       "      <td>0.584214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloomberg</th>\n",
       "      <td>0.604432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401390</td>\n",
       "      <td>0.626982</td>\n",
       "      <td>0.646044</td>\n",
       "      <td>0.475183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breitbart</th>\n",
       "      <td>0.533233</td>\n",
       "      <td>0.401390</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581852</td>\n",
       "      <td>0.608903</td>\n",
       "      <td>0.512336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>0.836252</td>\n",
       "      <td>0.626982</td>\n",
       "      <td>0.581852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810445</td>\n",
       "      <td>0.610755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.799638</td>\n",
       "      <td>0.646044</td>\n",
       "      <td>0.608903</td>\n",
       "      <td>0.810445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natl review</th>\n",
       "      <td>0.584214</td>\n",
       "      <td>0.475183</td>\n",
       "      <td>0.512336</td>\n",
       "      <td>0.610755</td>\n",
       "      <td>0.601729</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 WaPo  bloomberg  breitbart       cnn       fox  natl review\n",
       "WaPo         1.000000   0.604432   0.533233  0.836252  0.799638     0.584214\n",
       "bloomberg    0.604432   1.000000   0.401390  0.626982  0.646044     0.475183\n",
       "breitbart    0.533233   0.401390   1.000000  0.581852  0.608903     0.512336\n",
       "cnn          0.836252   0.626982   0.581852  1.000000  0.810445     0.610755\n",
       "fox          0.799638   0.646044   0.608903  0.810445  1.000000     0.601729\n",
       "natl review  0.584214   0.475183   0.512336  0.610755  0.601729     1.000000"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_mat = cosine_similarities_mat(tfidf)\n",
    "df_cs = pd.DataFrame(cs_mat, columns = names, index = names)\n",
    "df_cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WaPo</th>\n",
       "      <th>bloomberg</th>\n",
       "      <th>breitbart</th>\n",
       "      <th>cnn</th>\n",
       "      <th>fox</th>\n",
       "      <th>natl review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WaPo</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588340</td>\n",
       "      <td>0.507521</td>\n",
       "      <td>0.828452</td>\n",
       "      <td>0.789826</td>\n",
       "      <td>0.560692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bloomberg</th>\n",
       "      <td>0.588340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.370086</td>\n",
       "      <td>0.609752</td>\n",
       "      <td>0.629160</td>\n",
       "      <td>0.446871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breitbart</th>\n",
       "      <td>0.507521</td>\n",
       "      <td>0.370086</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.553654</td>\n",
       "      <td>0.580424</td>\n",
       "      <td>0.472199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn</th>\n",
       "      <td>0.828452</td>\n",
       "      <td>0.609752</td>\n",
       "      <td>0.553654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.583096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fox</th>\n",
       "      <td>0.789826</td>\n",
       "      <td>0.629160</td>\n",
       "      <td>0.580424</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.570893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natl review</th>\n",
       "      <td>0.560692</td>\n",
       "      <td>0.446871</td>\n",
       "      <td>0.472199</td>\n",
       "      <td>0.583096</td>\n",
       "      <td>0.570893</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 WaPo  bloomberg  breitbart       cnn       fox  natl review\n",
       "WaPo         1.000000   0.588340   0.507521  0.828452  0.789826     0.560692\n",
       "bloomberg    0.588340   1.000000   0.370086  0.609752  0.629160     0.446871\n",
       "breitbart    0.507521   0.370086   1.000000  0.553654  0.580424     0.472199\n",
       "cnn          0.828452   0.609752   0.553654  1.000000  0.798319     0.583096\n",
       "fox          0.789826   0.629160   0.580424  0.798319  1.000000     0.570893\n",
       "natl review  0.560692   0.446871   0.472199  0.583096  0.570893     1.000000"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc_mat = pearson_corr_mat(tfidf)\n",
    "df_pc = pd.DataFrame(pc_mat, columns = names, index = names)\n",
    "df_pc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_text (file):\n",
    "    with open(file,'r') as f:\n",
    "        text = f.read()\n",
    "    f.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bb = read_text('data/breitbart_pol_feb_20_26.txt')\n",
    "nyt = read_text('data/nyt_pol_feb_20_26.txt')\n",
    "hp = read_text('data/huffpost_pol_feb_20_26.txt')\n",
    "fox = read_text('data/fox_pol_feb_20_26.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = [bb,nyt,fox,hp]\n",
    "names = [\"breitbart\",\"nyt\",\"fox\",\"hp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopWords = stopwords.words('english')\n",
    "tokenize = lambda doc: list(filter(None,re.split(r\"\\W|\\d\",doc.lower())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(stop_words = stopWords,tokenizer=tokenize)\n",
    "tfidf = tfidf_vec.fit_transform(d)\n",
    "#print(td_mat.shape)\n",
    "#count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tf and tf-idf\n",
    "# tf_transformer = TfidfTransformer(use_idf=False)\n",
    "# tf = tf_transformer.fit_transform(td_mat)\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# tfidf = tfidf_transformer.fit_transform(td_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_features = 50,stop_words = stopWords,tokenizer=tokenize)\n",
    "td_mat = count_vect.fit_transform(d)\n",
    "#count_vect.get_feature_names()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf = tfidf_transformer.fit_transform(td_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity(d1, d2):\n",
    "    intersection = set(d1).intersection(set(d2))\n",
    "    union = set(d1).union(set(d2))\n",
    "    return len(intersection)/len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_tokenized =[tokenize(doc) for doc in d]\n",
    "d_no_stop =[[w for w in d if w not in stopWords] for d in d_tokenized]\n",
    "d_Freq =[FreqDist(doc) for doc in d_no_stop]\n",
    "d_common_50 =[f.most_common(50) for f in d_Freq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_most_common_words = [list(zip(*d))[0] for d in d_common_50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def jaccard_similarity_mat(m):\n",
    "    n = len(m)\n",
    "    array = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i,n):\n",
    "            sim = jaccard_similarity(m[i],m[j])\n",
    "            array[i][j] = sim\n",
    "            array[j][i] = sim\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.2987013 ,  0.36986301,  0.33333333],\n",
       "       [ 0.2987013 ,  1.        ,  0.36986301,  0.35135135],\n",
       "       [ 0.36986301,  0.36986301,  1.        ,  0.42857143],\n",
       "       [ 0.33333333,  0.35135135,  0.42857143,  1.        ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similarity_mat(d_most_common_words)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
